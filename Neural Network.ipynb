{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b05e588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pathlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17f9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yes_dir = os.path.join('D:/Datasets/pizzanotpizza/pizza_not_pizza/train/yes')\n",
    "train_no_dir = os.path.join('D:/Datasets/pizzanotpizza/pizza_not_pizza/train/no')\n",
    "valid_yes_dir = os.path.join('D:/Datasets/pizzanotpizza/pizza_not_pizza/valid/yes')\n",
    "valid_no_dir = os.path.join('D:/Datasets/pizzanotpizza/pizza_not_pizza/valid/no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c666ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db56286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1442 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'D:/Datasets/pizzanotpizza/pizza_not_pizza/train/',\n",
    "        classes = ['yes', 'no'],\n",
    "        target_size=(255, 255),\n",
    "        batch_size=1442,\n",
    "        class_mode='binary',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d2bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 524 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'D:/Datasets/pizzanotpizza/pizza_not_pizza/valid/',\n",
    "        classes = ['yes', 'no'],\n",
    "        target_size=(255, 255),\n",
    "        batch_size=524,\n",
    "        class_mode='binary',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21fb199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1f3cae3cdc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44738dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a05d018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e36d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.22352943, 0.14901961, 0.09411766],\n",
       "         [0.2392157 , 0.16470589, 0.10980393],\n",
       "         [0.25490198, 0.16862746, 0.1254902 ],\n",
       "         ...,\n",
       "         [0.10588236, 0.10588236, 0.13725491],\n",
       "         [0.10588236, 0.10980393, 0.12941177],\n",
       "         [0.09019608, 0.09411766, 0.10980393]],\n",
       "\n",
       "        [[0.2392157 , 0.15294118, 0.09803922],\n",
       "         [0.2509804 , 0.16470589, 0.10980393],\n",
       "         [0.26666668, 0.17254902, 0.1254902 ],\n",
       "         ...,\n",
       "         [0.09803922, 0.09803922, 0.12941177],\n",
       "         [0.09019608, 0.09019608, 0.12156864],\n",
       "         [0.09411766, 0.09803922, 0.11764707]],\n",
       "\n",
       "        [[0.23529413, 0.14509805, 0.09019608],\n",
       "         [0.25490198, 0.16470589, 0.10980393],\n",
       "         [0.2784314 , 0.1764706 , 0.1254902 ],\n",
       "         ...,\n",
       "         [0.09411766, 0.09411766, 0.13333334],\n",
       "         [0.09019608, 0.09019608, 0.12156864],\n",
       "         [0.09803922, 0.09411766, 0.1254902 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0509804 , 0.02352941, 0.        ],\n",
       "         [0.04313726, 0.02352941, 0.00784314],\n",
       "         [0.03137255, 0.02745098, 0.01960784],\n",
       "         ...,\n",
       "         [0.8588236 , 0.8705883 , 0.80392164],\n",
       "         [0.8705883 , 0.8745099 , 0.8196079 ],\n",
       "         [0.87843144, 0.87843144, 0.8313726 ]],\n",
       "\n",
       "        [[0.04705883, 0.02745098, 0.01176471],\n",
       "         [0.04313726, 0.02745098, 0.01568628],\n",
       "         [0.03137255, 0.03137255, 0.02352941],\n",
       "         ...,\n",
       "         [0.85098046, 0.86274517, 0.7960785 ],\n",
       "         [0.86274517, 0.8705883 , 0.8196079 ],\n",
       "         [0.8745099 , 0.8745099 , 0.8352942 ]],\n",
       "\n",
       "        [[0.3019608 , 0.29803923, 0.31764707],\n",
       "         [0.3019608 , 0.30980393, 0.30588236],\n",
       "         [0.29411766, 0.3137255 , 0.29803923],\n",
       "         ...,\n",
       "         [0.90196085, 0.909804  , 0.854902  ],\n",
       "         [0.91372555, 0.9215687 , 0.87843144],\n",
       "         [0.9176471 , 0.9215687 , 0.8980393 ]]],\n",
       "\n",
       "\n",
       "       [[[0.08627451, 0.05490196, 0.04313726],\n",
       "         [0.08627451, 0.05882353, 0.03529412],\n",
       "         [0.08627451, 0.05882353, 0.03529412],\n",
       "         ...,\n",
       "         [0.12941177, 0.10196079, 0.03921569],\n",
       "         [0.1254902 , 0.09803922, 0.03529412],\n",
       "         [0.12156864, 0.09019608, 0.03921569]],\n",
       "\n",
       "        [[0.08235294, 0.0509804 , 0.03921569],\n",
       "         [0.08235294, 0.05490196, 0.03137255],\n",
       "         [0.08235294, 0.05490196, 0.03137255],\n",
       "         ...,\n",
       "         [0.12156864, 0.09411766, 0.03137255],\n",
       "         [0.1254902 , 0.09803922, 0.03529412],\n",
       "         [0.13333334, 0.10196079, 0.0509804 ]],\n",
       "\n",
       "        [[0.07058824, 0.03921569, 0.02745098],\n",
       "         [0.07450981, 0.04705883, 0.02352941],\n",
       "         [0.07843138, 0.0509804 , 0.02745098],\n",
       "         ...,\n",
       "         [0.13725491, 0.1137255 , 0.0509804 ],\n",
       "         [0.13333334, 0.10980393, 0.04705883],\n",
       "         [0.13333334, 0.10980393, 0.05490196]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.69411767, 0.70980394, 0.7137255 ],\n",
       "         [0.68235296, 0.69803923, 0.7019608 ],\n",
       "         [0.69411767, 0.70980394, 0.7137255 ],\n",
       "         ...,\n",
       "         [0.46274513, 0.47450984, 0.44705886],\n",
       "         [0.4666667 , 0.4784314 , 0.45098042],\n",
       "         [0.4666667 , 0.4784314 , 0.45098042]],\n",
       "\n",
       "        [[0.6666667 , 0.67058825, 0.6784314 ],\n",
       "         [0.6627451 , 0.6784314 , 0.68235296],\n",
       "         [0.6745098 , 0.6901961 , 0.69411767],\n",
       "         ...,\n",
       "         [0.46274513, 0.47450984, 0.44705886],\n",
       "         [0.47058827, 0.48235297, 0.454902  ],\n",
       "         [0.45098042, 0.46274513, 0.43529415]],\n",
       "\n",
       "        [[0.65882355, 0.6666667 , 0.6627451 ],\n",
       "         [0.6784314 , 0.6862745 , 0.68235296],\n",
       "         [0.6784314 , 0.69411767, 0.6901961 ],\n",
       "         ...,\n",
       "         [0.47450984, 0.48627454, 0.45882356],\n",
       "         [0.47058827, 0.48235297, 0.454902  ],\n",
       "         [0.454902  , 0.4666667 , 0.43921572]]],\n",
       "\n",
       "\n",
       "       [[[0.19215688, 0.08627451, 0.01960784],\n",
       "         [0.19215688, 0.08235294, 0.03529412],\n",
       "         [0.18431373, 0.07450981, 0.03137255],\n",
       "         ...,\n",
       "         [0.08627451, 0.03137255, 0.03137255],\n",
       "         [0.08627451, 0.03137255, 0.03137255],\n",
       "         [0.10588236, 0.04313726, 0.04705883]],\n",
       "\n",
       "        [[0.19607845, 0.09019608, 0.02352941],\n",
       "         [0.18431373, 0.07450981, 0.01960784],\n",
       "         [0.18039216, 0.07058824, 0.02745098],\n",
       "         ...,\n",
       "         [0.10980393, 0.05490196, 0.05490196],\n",
       "         [0.1137255 , 0.05882353, 0.05882353],\n",
       "         [0.10588236, 0.04313726, 0.04705883]],\n",
       "\n",
       "        [[0.18431373, 0.07058824, 0.00784314],\n",
       "         [0.18431373, 0.07450981, 0.01960784],\n",
       "         [0.18431373, 0.07450981, 0.03137255],\n",
       "         ...,\n",
       "         [0.10196079, 0.03921569, 0.03921569],\n",
       "         [0.10196079, 0.03921569, 0.03921569],\n",
       "         [0.10980393, 0.04705883, 0.04705883]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5411765 , 0.29803923, 0.06666667],\n",
       "         [0.52156866, 0.28627452, 0.0509804 ],\n",
       "         [0.52156866, 0.2901961 , 0.05490196],\n",
       "         ...,\n",
       "         [0.34509805, 0.21960786, 0.03529412],\n",
       "         [0.3529412 , 0.22352943, 0.0627451 ],\n",
       "         [0.3529412 , 0.21568629, 0.09019608]],\n",
       "\n",
       "        [[0.5058824 , 0.27450982, 0.04705883],\n",
       "         [0.5019608 , 0.28235295, 0.0509804 ],\n",
       "         [0.47450984, 0.25882354, 0.03529412],\n",
       "         ...,\n",
       "         [0.36862746, 0.2392157 , 0.03921569],\n",
       "         [0.36078432, 0.22352943, 0.05882353],\n",
       "         [0.37647063, 0.23529413, 0.10196079]],\n",
       "\n",
       "        [[0.48627454, 0.26666668, 0.04313726],\n",
       "         [0.48235297, 0.2784314 , 0.0509804 ],\n",
       "         [0.48627454, 0.28627452, 0.0627451 ],\n",
       "         ...,\n",
       "         [0.41176474, 0.28235295, 0.07450981],\n",
       "         [0.39607847, 0.2627451 , 0.08235294],\n",
       "         [0.41960788, 0.27058825, 0.1254902 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.16470589, 0.17254902, 0.16078432],\n",
       "         [0.16078432, 0.16078432, 0.15294118],\n",
       "         [0.16470589, 0.14901961, 0.14509805],\n",
       "         ...,\n",
       "         [0.27450982, 0.21568629, 0.14117648],\n",
       "         [0.29411766, 0.24313727, 0.16862746],\n",
       "         [0.3019608 , 0.2509804 , 0.1764706 ]],\n",
       "\n",
       "        [[0.15686275, 0.16470589, 0.15294118],\n",
       "         [0.15686275, 0.15686275, 0.14901961],\n",
       "         [0.16470589, 0.14901961, 0.14509805],\n",
       "         ...,\n",
       "         [0.27450982, 0.21568629, 0.14117648],\n",
       "         [0.29411766, 0.24313727, 0.16862746],\n",
       "         [0.29411766, 0.24313727, 0.16862746]],\n",
       "\n",
       "        [[0.16862746, 0.16862746, 0.16078432],\n",
       "         [0.16470589, 0.16078432, 0.15294118],\n",
       "         [0.16470589, 0.14901961, 0.14509805],\n",
       "         ...,\n",
       "         [0.28235295, 0.22352943, 0.14901961],\n",
       "         [0.30980393, 0.2509804 , 0.1764706 ],\n",
       "         [0.28627452, 0.227451  , 0.15294118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.13725491, 0.12156864, 0.07843138],\n",
       "         [0.11764707, 0.10196079, 0.06666667],\n",
       "         [0.15686275, 0.12941177, 0.10588236],\n",
       "         ...,\n",
       "         [0.2392157 , 0.17254902, 0.10196079],\n",
       "         [0.2392157 , 0.17254902, 0.10196079],\n",
       "         [0.227451  , 0.16078432, 0.09019608]],\n",
       "\n",
       "        [[0.14901961, 0.13333334, 0.09019608],\n",
       "         [0.14117648, 0.1254902 , 0.09019608],\n",
       "         [0.22352943, 0.20392159, 0.18039216],\n",
       "         ...,\n",
       "         [0.23529413, 0.16862746, 0.09803922],\n",
       "         [0.23529413, 0.16862746, 0.09803922],\n",
       "         [0.22352943, 0.15686275, 0.08627451]],\n",
       "\n",
       "        [[0.12941177, 0.12156864, 0.07058824],\n",
       "         [0.12941177, 0.11764707, 0.08235294],\n",
       "         [0.13333334, 0.1137255 , 0.09019608],\n",
       "         ...,\n",
       "         [0.24313727, 0.1764706 , 0.1137255 ],\n",
       "         [0.2392157 , 0.17254902, 0.10980393],\n",
       "         [0.2392157 , 0.17254902, 0.10980393]]],\n",
       "\n",
       "\n",
       "       [[[0.01568628, 0.01960784, 0.        ],\n",
       "         [0.02352941, 0.02745098, 0.00784314],\n",
       "         [0.02352941, 0.02745098, 0.00784314],\n",
       "         ...,\n",
       "         [0.01568628, 0.02745098, 0.        ],\n",
       "         [0.01568628, 0.02745098, 0.        ],\n",
       "         [0.01176471, 0.02352941, 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.01176471, 0.        ],\n",
       "         [0.01960784, 0.02352941, 0.00392157],\n",
       "         [0.01960784, 0.02352941, 0.00392157],\n",
       "         ...,\n",
       "         [0.00392157, 0.01176471, 0.        ],\n",
       "         [0.00392157, 0.01176471, 0.        ],\n",
       "         [0.02352941, 0.03137255, 0.01176471]],\n",
       "\n",
       "        [[0.01568628, 0.01176471, 0.        ],\n",
       "         [0.02745098, 0.02352941, 0.00392157],\n",
       "         [0.02352941, 0.02745098, 0.00392157],\n",
       "         ...,\n",
       "         [0.01176471, 0.01960784, 0.        ],\n",
       "         [0.01176471, 0.01960784, 0.        ],\n",
       "         [0.02352941, 0.03137255, 0.01960784]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.02745098, 0.00392157],\n",
       "         [0.01176471, 0.03137255, 0.00784314],\n",
       "         [0.01176471, 0.03137255, 0.00784314],\n",
       "         ...,\n",
       "         [0.01960784, 0.0509804 , 0.        ],\n",
       "         [0.01960784, 0.0509804 , 0.        ],\n",
       "         [0.01568628, 0.04705883, 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.02745098, 0.00392157],\n",
       "         [0.01176471, 0.03137255, 0.00784314],\n",
       "         [0.01176471, 0.03137255, 0.00784314],\n",
       "         ...,\n",
       "         [0.01960784, 0.0509804 , 0.        ],\n",
       "         [0.01960784, 0.0509804 , 0.        ],\n",
       "         [0.01960784, 0.0509804 , 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.02745098, 0.00392157],\n",
       "         [0.01176471, 0.03137255, 0.00784314],\n",
       "         [0.01176471, 0.03137255, 0.00784314],\n",
       "         ...,\n",
       "         [0.01960784, 0.0509804 , 0.        ],\n",
       "         [0.01960784, 0.0509804 , 0.        ],\n",
       "         [0.02352941, 0.05490196, 0.00392157]]],\n",
       "\n",
       "\n",
       "       [[[0.5529412 , 0.40784317, 0.23529413],\n",
       "         [0.6509804 , 0.50980395, 0.32156864],\n",
       "         [0.7490196 , 0.60784316, 0.41176474],\n",
       "         ...,\n",
       "         [0.0509804 , 0.04313726, 0.05490196],\n",
       "         [0.0509804 , 0.04313726, 0.05490196],\n",
       "         [0.04705883, 0.04705883, 0.05490196]],\n",
       "\n",
       "        [[0.79215693, 0.6509804 , 0.46274513],\n",
       "         [0.8000001 , 0.654902  , 0.45098042],\n",
       "         [0.8196079 , 0.6745098 , 0.4666667 ],\n",
       "         ...,\n",
       "         [0.06666667, 0.04313726, 0.0509804 ],\n",
       "         [0.05882353, 0.03529412, 0.04313726],\n",
       "         [0.0509804 , 0.03137255, 0.04705883]],\n",
       "\n",
       "        [[0.82745105, 0.67058825, 0.4666667 ],\n",
       "         [0.83921576, 0.6862745 , 0.47058827],\n",
       "         [0.81568635, 0.6627451 , 0.43921572],\n",
       "         ...,\n",
       "         [0.0627451 , 0.02745098, 0.03921569],\n",
       "         [0.05490196, 0.01960784, 0.03137255],\n",
       "         [0.05490196, 0.01960784, 0.03137255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9568628 , 0.93725497, 0.9215687 ],\n",
       "         [0.9607844 , 0.94117653, 0.92549026],\n",
       "         [0.9607844 , 0.9490197 , 0.9294118 ],\n",
       "         ...,\n",
       "         [0.9333334 , 0.9725491 , 0.9686275 ],\n",
       "         [0.94117653, 0.9803922 , 0.97647065],\n",
       "         [0.9333334 , 0.9725491 , 0.9686275 ]],\n",
       "\n",
       "        [[0.9607844 , 0.94117653, 0.92549026],\n",
       "         [0.9607844 , 0.94117653, 0.92549026],\n",
       "         [0.9568628 , 0.9450981 , 0.92549026],\n",
       "         ...,\n",
       "         [0.94117653, 0.9803922 , 0.97647065],\n",
       "         [0.94117653, 0.9803922 , 0.97647065],\n",
       "         [0.93725497, 0.97647065, 0.9725491 ]],\n",
       "\n",
       "        [[0.9607844 , 0.94117653, 0.92549026],\n",
       "         [0.9607844 , 0.94117653, 0.92549026],\n",
       "         [0.9568628 , 0.9450981 , 0.92549026],\n",
       "         ...,\n",
       "         [0.94117653, 0.9803922 , 0.97647065],\n",
       "         [0.9294118 , 0.9686275 , 0.96470594],\n",
       "         [0.9450981 , 0.9843138 , 0.9803922 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8514efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = validation_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86bab30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 255, 255, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c6bd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1183d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten(input_shape=(255, 255, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab1af1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 195075)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8e2c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(15):\n",
    "    model.add(tf.keras.layers.Dense(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f030488",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be6379b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce4f25a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 6.0896 - accuracy: 0.5187 - val_loss: 0.6838 - val_accuracy: 0.5802\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.7075 - accuracy: 0.6408 - val_loss: 0.6423 - val_accuracy: 0.6603\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6244 - accuracy: 0.6588 - val_loss: 0.6959 - val_accuracy: 0.5897\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6145 - accuracy: 0.6505 - val_loss: 0.6545 - val_accuracy: 0.6412\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5841 - accuracy: 0.6990 - val_loss: 0.6353 - val_accuracy: 0.6584\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5649 - accuracy: 0.7129 - val_loss: 0.7081 - val_accuracy: 0.5821\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5850 - accuracy: 0.6872 - val_loss: 0.7427 - val_accuracy: 0.5840\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6290 - accuracy: 0.6678 - val_loss: 1.3215 - val_accuracy: 0.5095\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6039 - accuracy: 0.6907 - val_loss: 0.7424 - val_accuracy: 0.5973\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5390 - accuracy: 0.7379 - val_loss: 0.8296 - val_accuracy: 0.5668\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5691 - accuracy: 0.7143 - val_loss: 0.6690 - val_accuracy: 0.6412\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5098 - accuracy: 0.7517 - val_loss: 0.8259 - val_accuracy: 0.5744\n",
      "Epoch 13/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5095 - accuracy: 0.7573 - val_loss: 0.6773 - val_accuracy: 0.6641\n",
      "Epoch 14/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5001 - accuracy: 0.7503 - val_loss: 0.7252 - val_accuracy: 0.6298\n",
      "Epoch 15/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5076 - accuracy: 0.7365 - val_loss: 0.6311 - val_accuracy: 0.6412\n",
      "Epoch 16/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5049 - accuracy: 0.7635 - val_loss: 1.0460 - val_accuracy: 0.5286\n",
      "Epoch 17/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5398 - accuracy: 0.7434 - val_loss: 0.6355 - val_accuracy: 0.6603\n",
      "Epoch 18/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.4057 - accuracy: 0.8211 - val_loss: 1.3348 - val_accuracy: 0.5496\n",
      "Epoch 19/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5178 - accuracy: 0.7524 - val_loss: 1.4233 - val_accuracy: 0.5172\n",
      "Epoch 20/20\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.4842 - accuracy: 0.7795 - val_loss: 1.6476 - val_accuracy: 0.5248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4291a71c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=20, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa9eb20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.4985 - accuracy: 0.7698 - val_loss: 0.9965 - val_accuracy: 0.5611\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.4048 - accuracy: 0.8197 - val_loss: 0.7489 - val_accuracy: 0.6374\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.4777 - accuracy: 0.8107 - val_loss: 0.9340 - val_accuracy: 0.5573\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.4095 - accuracy: 0.8183 - val_loss: 0.8232 - val_accuracy: 0.6469\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.3695 - accuracy: 0.8405 - val_loss: 1.5301 - val_accuracy: 0.5172\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.5553 - accuracy: 0.7607 - val_loss: 0.6151 - val_accuracy: 0.6469\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.3698 - accuracy: 0.8419 - val_loss: 0.9703 - val_accuracy: 0.5897\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.3424 - accuracy: 0.8426 - val_loss: 1.2537 - val_accuracy: 0.6011\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.3824 - accuracy: 0.8315 - val_loss: 1.0711 - val_accuracy: 0.5687\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.3441 - accuracy: 0.8509 - val_loss: 1.7521 - val_accuracy: 0.5458\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.3007 - accuracy: 0.8641 - val_loss: 0.9049 - val_accuracy: 0.6355\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.2431 - accuracy: 0.8994 - val_loss: 1.0960 - val_accuracy: 0.6183\n",
      "Epoch 13/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.3468 - accuracy: 0.8509 - val_loss: 0.8074 - val_accuracy: 0.6393\n",
      "Epoch 14/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.2293 - accuracy: 0.9133 - val_loss: 4.9941 - val_accuracy: 0.5038\n",
      "Epoch 15/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.9798 - accuracy: 0.5818 - val_loss: 0.6577 - val_accuracy: 0.6469\n",
      "Epoch 16/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.4057 - accuracy: 0.8121 - val_loss: 0.8025 - val_accuracy: 0.6622\n",
      "Epoch 17/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.3177 - accuracy: 0.8655 - val_loss: 1.3466 - val_accuracy: 0.5782\n",
      "Epoch 18/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.2614 - accuracy: 0.9043 - val_loss: 1.2626 - val_accuracy: 0.6011\n",
      "Epoch 19/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.3354 - accuracy: 0.8842 - val_loss: 1.1985 - val_accuracy: 0.5840\n",
      "Epoch 20/20\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.2820 - accuracy: 0.8870 - val_loss: 0.9323 - val_accuracy: 0.6355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f42bce3ee0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=20, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61bc00b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.9323 - accuracy: 0.6355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.932309091091156, 0.635496199131012]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c5dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "911c3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.add(tf.keras.layers.Flatten(input_shape=(255,255,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a0c8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(15):\n",
    "    model2.add(tf.keras.layers.Dense(20, kernel_regularizer='l2'))\n",
    "    model2.add(tf.keras.layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbf5c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2adbd6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 195075)            0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 20)                3901520   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,907,761\n",
      "Trainable params: 3,907,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c213ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aefc171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "46/46 [==============================] - 2s 31ms/step - loss: 2.6650 - accuracy: 0.4889 - val_loss: 2.4281 - val_accuracy: 0.5057\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 2.3934 - accuracy: 0.5298 - val_loss: 2.3516 - val_accuracy: 0.6031\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 2.3295 - accuracy: 0.5576 - val_loss: 2.2944 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 2.2520 - accuracy: 0.5479 - val_loss: 2.2073 - val_accuracy: 0.6031\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 2.1744 - accuracy: 0.5513 - val_loss: 2.1273 - val_accuracy: 0.6489\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 2.1056 - accuracy: 0.5818 - val_loss: 2.0602 - val_accuracy: 0.5191\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 2.0353 - accuracy: 0.5284 - val_loss: 1.9908 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.9586 - accuracy: 0.5208 - val_loss: 1.9213 - val_accuracy: 0.5954\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.8902 - accuracy: 0.5333 - val_loss: 1.8556 - val_accuracy: 0.5363\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.8296 - accuracy: 0.5187 - val_loss: 1.7946 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.7674 - accuracy: 0.5125 - val_loss: 1.7354 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.7083 - accuracy: 0.5222 - val_loss: 1.6786 - val_accuracy: 0.5763\n",
      "Epoch 13/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.6550 - accuracy: 0.4917 - val_loss: 1.6267 - val_accuracy: 0.5573\n",
      "Epoch 14/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.6027 - accuracy: 0.5049 - val_loss: 1.5767 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.5545 - accuracy: 0.4931 - val_loss: 1.5293 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.5084 - accuracy: 0.4854 - val_loss: 1.4848 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.4649 - accuracy: 0.4896 - val_loss: 1.4429 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.4242 - accuracy: 0.5028 - val_loss: 1.4033 - val_accuracy: 0.5000\n",
      "Epoch 19/20\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 1.3856 - accuracy: 0.4792 - val_loss: 1.3659 - val_accuracy: 0.5000\n",
      "Epoch 20/20\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 1.3494 - accuracy: 0.5000 - val_loss: 1.3305 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f42bd35160>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x, y, epochs=20, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddc61e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 1.3145 - accuracy: 0.5000 - val_loss: 1.2971 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 1.2826 - accuracy: 0.5000 - val_loss: 1.2654 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.2513 - accuracy: 0.4889 - val_loss: 1.2355 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 1.2220 - accuracy: 0.4861 - val_loss: 1.2071 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 1.1950 - accuracy: 0.4681 - val_loss: 1.1803 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 1.1684 - accuracy: 0.5000 - val_loss: 1.1548 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.1433 - accuracy: 0.5000 - val_loss: 1.1308 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.1199 - accuracy: 0.4778 - val_loss: 1.1078 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.0978 - accuracy: 0.5000 - val_loss: 1.0861 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 1.0763 - accuracy: 0.4945 - val_loss: 1.0655 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 1.0563 - accuracy: 0.5028 - val_loss: 1.0458 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 1.0371 - accuracy: 0.4778 - val_loss: 1.0272 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 1.0189 - accuracy: 0.4834 - val_loss: 1.0095 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 1.0018 - accuracy: 0.4653 - val_loss: 0.9928 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.9855 - accuracy: 0.5000 - val_loss: 0.9768 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.9698 - accuracy: 0.4847 - val_loss: 0.9617 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.9553 - accuracy: 0.5000 - val_loss: 0.9472 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.9408 - accuracy: 0.4917 - val_loss: 0.9336 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.9280 - accuracy: 0.4834 - val_loss: 0.9206 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.9154 - accuracy: 0.5000 - val_loss: 0.9083 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.9035 - accuracy: 0.4709 - val_loss: 0.8966 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.8918 - accuracy: 0.5000 - val_loss: 0.8855 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.8804 - accuracy: 0.4806 - val_loss: 0.8748 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.8702 - accuracy: 0.5000 - val_loss: 0.8649 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.8604 - accuracy: 0.5000 - val_loss: 0.8552 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.8510 - accuracy: 0.4889 - val_loss: 0.8462 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.8421 - accuracy: 0.5000 - val_loss: 0.8376 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.8339 - accuracy: 0.4875 - val_loss: 0.8294 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.8259 - accuracy: 0.4792 - val_loss: 0.8217 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.8184 - accuracy: 0.4861 - val_loss: 0.8143 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f42fdc5eb0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x,y, epochs=30, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bded87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8afa43a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.add(tf.keras.layers.Flatten(input_shape=(255,255,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ca54fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    model3.add(tf.keras.layers.Dense(100, kernel_regularizer='l2'))\n",
    "    tf.keras.layers.Dropout(rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c810e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d135e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 195075)            0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 100)               19507600  \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,548,101\n",
      "Trainable params: 19,548,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a12bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model3.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45df4fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46/46 [==============================] - 5s 108ms/step - loss: 31.5401 - accuracy: 0.5326 - val_loss: 6.5811 - val_accuracy: 0.5763\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 5s 105ms/step - loss: 6.3481 - accuracy: 0.6130 - val_loss: 5.8628 - val_accuracy: 0.6679\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 5s 105ms/step - loss: 5.6247 - accuracy: 0.6727 - val_loss: 5.5517 - val_accuracy: 0.5878\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 5s 106ms/step - loss: 5.2319 - accuracy: 0.6803 - val_loss: 5.1774 - val_accuracy: 0.5821\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 5.0013 - accuracy: 0.6394 - val_loss: 4.9565 - val_accuracy: 0.6183\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 5s 106ms/step - loss: 4.7871 - accuracy: 0.6879 - val_loss: 4.7860 - val_accuracy: 0.5802\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.7539 - accuracy: 0.6463 - val_loss: 4.8509 - val_accuracy: 0.5744\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 16.9621 - accuracy: 0.5104 - val_loss: 6.6842 - val_accuracy: 0.5573\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 5s 106ms/step - loss: 5.3981 - accuracy: 0.6151 - val_loss: 4.9084 - val_accuracy: 0.5477\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.6336 - accuracy: 0.6859 - val_loss: 4.5733 - val_accuracy: 0.6374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f42fe238b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x, y, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47760ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "46/46 [==============================] - 5s 108ms/step - loss: 4.4757 - accuracy: 0.7032 - val_loss: 4.4636 - val_accuracy: 0.6546\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 5s 106ms/step - loss: 4.4166 - accuracy: 0.6727 - val_loss: 4.4770 - val_accuracy: 0.5630\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.4189 - accuracy: 0.6255 - val_loss: 4.3745 - val_accuracy: 0.6565\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 5s 106ms/step - loss: 4.3510 - accuracy: 0.6671 - val_loss: 4.3390 - val_accuracy: 0.6584\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 4.3014 - accuracy: 0.6990 - val_loss: 4.4362 - val_accuracy: 0.5630\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 5s 112ms/step - loss: 4.2961 - accuracy: 0.6706 - val_loss: 4.3585 - val_accuracy: 0.5859\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.2714 - accuracy: 0.6678 - val_loss: 4.2740 - val_accuracy: 0.6603\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.2841 - accuracy: 0.6463 - val_loss: 4.2796 - val_accuracy: 0.6240\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.2121 - accuracy: 0.6845 - val_loss: 4.4486 - val_accuracy: 0.5344\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.2195 - accuracy: 0.6644 - val_loss: 4.5785 - val_accuracy: 0.5248\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.3013 - accuracy: 0.6325 - val_loss: 4.1784 - val_accuracy: 0.6431\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.1510 - accuracy: 0.6699 - val_loss: 4.2078 - val_accuracy: 0.6107\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.1287 - accuracy: 0.6623 - val_loss: 4.2204 - val_accuracy: 0.5573\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 4.1504 - accuracy: 0.6304 - val_loss: 4.1484 - val_accuracy: 0.6050\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 5s 108ms/step - loss: 4.0643 - accuracy: 0.6914 - val_loss: 4.3880 - val_accuracy: 0.5095\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 5s 109ms/step - loss: 4.0260 - accuracy: 0.6907 - val_loss: 4.1549 - val_accuracy: 0.5363\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 3.9977 - accuracy: 0.6727 - val_loss: 4.0277 - val_accuracy: 0.6489\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 3.9581 - accuracy: 0.6831 - val_loss: 4.1251 - val_accuracy: 0.5344\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 3.9609 - accuracy: 0.6463 - val_loss: 4.1902 - val_accuracy: 0.5286\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 3.9146 - accuracy: 0.6803 - val_loss: 3.8976 - val_accuracy: 0.6508\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 5s 108ms/step - loss: 3.8629 - accuracy: 0.7101 - val_loss: 4.0224 - val_accuracy: 0.5496\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 5s 108ms/step - loss: 3.9052 - accuracy: 0.6429 - val_loss: 4.3029 - val_accuracy: 0.5057\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 5s 108ms/step - loss: 4.3697 - accuracy: 0.5811 - val_loss: 4.2019 - val_accuracy: 0.5515\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 5s 109ms/step - loss: 3.8888 - accuracy: 0.6484 - val_loss: 3.8763 - val_accuracy: 0.5630\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 3.7841 - accuracy: 0.6526 - val_loss: 4.3204 - val_accuracy: 0.5057\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 3.8131 - accuracy: 0.6130 - val_loss: 5.0113 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 5s 108ms/step - loss: 3.8296 - accuracy: 0.6130 - val_loss: 4.2094 - val_accuracy: 0.5038\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 3.7815 - accuracy: 0.6047 - val_loss: 3.7737 - val_accuracy: 0.5630\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 3.6226 - accuracy: 0.6831 - val_loss: 3.6259 - val_accuracy: 0.6279\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 3.5546 - accuracy: 0.6935 - val_loss: 3.6329 - val_accuracy: 0.5840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f42ffe8970>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x, y, epochs=30, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8de89ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 195075)            0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 100)               19507600  \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,548,101\n",
      "Trainable params: 19,548,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a73744fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('5_layer_regularized_dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16ec4ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 195075)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                5852280   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,865,331\n",
      "Trainable params: 5,865,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1048531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    This function prints and plots the confusion matrix.\n",
    "\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "\n",
    "    if normalize:\n",
    "\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        cm = np.around(cm, decimals=2)\n",
    "\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "\n",
    "        print(\"Normalized confusion matrix\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "\n",
    "        plt.text(j, i, cm[i, j],\n",
    "\n",
    "                 horizontalalignment=\"center\",\n",
    "\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ed38592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'no']\n"
     ]
    }
   ],
   "source": [
    "target_names = []\n",
    "\n",
    "for key in train_generator.class_indices:\n",
    "\n",
    "    target_names.append(key)\n",
    "\n",
    "\n",
    "\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e98389d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model3.predict(validation_generator)\n",
    "# Get most likely class\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3882552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8289795 ],\n",
       "       [0.8932255 ],\n",
       "       [0.81370175],\n",
       "       [0.48337132],\n",
       "       [0.87788147],\n",
       "       [0.66816163],\n",
       "       [0.28165418],\n",
       "       [0.95732945],\n",
       "       [0.2551207 ],\n",
       "       [0.70102245],\n",
       "       [0.7187034 ],\n",
       "       [0.5170563 ],\n",
       "       [0.7462239 ],\n",
       "       [0.77659607],\n",
       "       [0.75080585],\n",
       "       [0.5897861 ],\n",
       "       [0.81236565],\n",
       "       [0.54875094],\n",
       "       [0.7370698 ],\n",
       "       [0.7523639 ],\n",
       "       [0.5168916 ],\n",
       "       [0.32430768],\n",
       "       [0.69719374],\n",
       "       [0.8201258 ],\n",
       "       [0.7963095 ],\n",
       "       [0.48871347],\n",
       "       [0.85642576],\n",
       "       [0.58707225],\n",
       "       [0.9131886 ],\n",
       "       [0.61085284],\n",
       "       [0.7884649 ],\n",
       "       [0.5590376 ],\n",
       "       [0.9142424 ],\n",
       "       [0.6716675 ],\n",
       "       [0.43520424],\n",
       "       [0.5842806 ],\n",
       "       [0.48173717],\n",
       "       [0.49871632],\n",
       "       [0.6925124 ],\n",
       "       [0.7662027 ],\n",
       "       [0.38665774],\n",
       "       [0.47130215],\n",
       "       [0.765726  ],\n",
       "       [0.7809179 ],\n",
       "       [0.6016744 ],\n",
       "       [0.22643352],\n",
       "       [0.6191138 ],\n",
       "       [0.8613255 ],\n",
       "       [0.7822757 ],\n",
       "       [0.49011257],\n",
       "       [0.2693585 ],\n",
       "       [0.3294857 ],\n",
       "       [0.64302146],\n",
       "       [0.56534123],\n",
       "       [0.6161098 ],\n",
       "       [0.57711935],\n",
       "       [0.9166379 ],\n",
       "       [0.89707786],\n",
       "       [0.7669453 ],\n",
       "       [0.2420946 ],\n",
       "       [0.5397997 ],\n",
       "       [0.4453048 ],\n",
       "       [0.61029965],\n",
       "       [0.69507873],\n",
       "       [0.8395816 ],\n",
       "       [0.86806023],\n",
       "       [0.56257534],\n",
       "       [0.7084618 ],\n",
       "       [0.858474  ],\n",
       "       [0.52167255],\n",
       "       [0.78981656],\n",
       "       [0.60323125],\n",
       "       [0.7758486 ],\n",
       "       [0.63990265],\n",
       "       [0.30184972],\n",
       "       [0.6370951 ],\n",
       "       [0.9099293 ],\n",
       "       [0.75633967],\n",
       "       [0.46659765],\n",
       "       [0.81180036],\n",
       "       [0.53902   ],\n",
       "       [0.49883276],\n",
       "       [0.84554195],\n",
       "       [0.48624995],\n",
       "       [0.8390641 ],\n",
       "       [0.68600863],\n",
       "       [0.94175196],\n",
       "       [0.79999244],\n",
       "       [0.94383955],\n",
       "       [0.42203847],\n",
       "       [0.7489397 ],\n",
       "       [0.94073534],\n",
       "       [0.6053861 ],\n",
       "       [0.92257154],\n",
       "       [0.77202654],\n",
       "       [0.4010262 ],\n",
       "       [0.497375  ],\n",
       "       [0.57806337],\n",
       "       [0.66940427],\n",
       "       [0.84627676],\n",
       "       [0.886825  ],\n",
       "       [0.4473021 ],\n",
       "       [0.59755135],\n",
       "       [0.6471911 ],\n",
       "       [0.73597306],\n",
       "       [0.6621094 ],\n",
       "       [0.14217785],\n",
       "       [0.6599181 ],\n",
       "       [0.80533785],\n",
       "       [0.82913315],\n",
       "       [0.7520964 ],\n",
       "       [0.595182  ],\n",
       "       [0.8387072 ],\n",
       "       [0.7141825 ],\n",
       "       [0.65001607],\n",
       "       [0.36885408],\n",
       "       [0.7897414 ],\n",
       "       [0.7896137 ],\n",
       "       [0.8545625 ],\n",
       "       [0.5652807 ],\n",
       "       [0.35855395],\n",
       "       [0.68630594],\n",
       "       [0.4716606 ],\n",
       "       [0.88160336],\n",
       "       [0.34144735],\n",
       "       [0.9135453 ],\n",
       "       [0.22922283],\n",
       "       [0.41269922],\n",
       "       [0.7589043 ],\n",
       "       [0.75629795],\n",
       "       [0.6085986 ],\n",
       "       [0.9232262 ],\n",
       "       [0.7826942 ],\n",
       "       [0.5619684 ],\n",
       "       [0.87559146],\n",
       "       [0.54142904],\n",
       "       [0.73725414],\n",
       "       [0.9717279 ],\n",
       "       [0.29429805],\n",
       "       [0.7542666 ],\n",
       "       [0.61959004],\n",
       "       [0.90125746],\n",
       "       [0.3036733 ],\n",
       "       [0.5290523 ],\n",
       "       [0.82653344],\n",
       "       [0.6561955 ],\n",
       "       [0.75787866],\n",
       "       [0.75932956],\n",
       "       [0.44660082],\n",
       "       [0.7696284 ],\n",
       "       [0.7617856 ],\n",
       "       [0.7048141 ],\n",
       "       [0.2811721 ],\n",
       "       [0.8569126 ],\n",
       "       [0.37383783],\n",
       "       [0.5384039 ],\n",
       "       [0.6799973 ],\n",
       "       [0.7085599 ],\n",
       "       [0.45895058],\n",
       "       [0.71570826],\n",
       "       [0.57729113],\n",
       "       [0.47980633],\n",
       "       [0.8323147 ],\n",
       "       [0.66648656],\n",
       "       [0.71409035],\n",
       "       [0.5927155 ],\n",
       "       [0.9200891 ],\n",
       "       [0.3800807 ],\n",
       "       [0.25869542],\n",
       "       [0.62201166],\n",
       "       [0.57755804],\n",
       "       [0.8778392 ],\n",
       "       [0.8557631 ],\n",
       "       [0.53445125],\n",
       "       [0.6874477 ],\n",
       "       [0.62074804],\n",
       "       [0.7896892 ],\n",
       "       [0.81776905],\n",
       "       [0.46748835],\n",
       "       [0.59299153],\n",
       "       [0.87745225],\n",
       "       [0.42503494],\n",
       "       [0.42687145],\n",
       "       [0.6860589 ],\n",
       "       [0.29071963],\n",
       "       [0.8331475 ],\n",
       "       [0.65176284],\n",
       "       [0.6938732 ],\n",
       "       [0.6940821 ],\n",
       "       [0.6092638 ],\n",
       "       [0.63177484],\n",
       "       [0.67439944],\n",
       "       [0.7558689 ],\n",
       "       [0.7353785 ],\n",
       "       [0.6091531 ],\n",
       "       [0.7153541 ],\n",
       "       [0.6847732 ],\n",
       "       [0.5917247 ],\n",
       "       [0.58373344],\n",
       "       [0.6957238 ],\n",
       "       [0.39877832],\n",
       "       [0.59672326],\n",
       "       [0.73431975],\n",
       "       [0.6879124 ],\n",
       "       [0.38908747],\n",
       "       [0.20758331],\n",
       "       [0.85678387],\n",
       "       [0.8450426 ],\n",
       "       [0.82651925],\n",
       "       [0.35488313],\n",
       "       [0.47231597],\n",
       "       [0.46233648],\n",
       "       [0.7436246 ],\n",
       "       [0.8632587 ],\n",
       "       [0.80964506],\n",
       "       [0.46492013],\n",
       "       [0.45313716],\n",
       "       [0.80113816],\n",
       "       [0.7697867 ],\n",
       "       [0.60239184],\n",
       "       [0.53570515],\n",
       "       [0.5870263 ],\n",
       "       [0.5540152 ],\n",
       "       [0.70524275],\n",
       "       [0.7626487 ],\n",
       "       [0.87123674],\n",
       "       [0.3573663 ],\n",
       "       [0.5908456 ],\n",
       "       [0.85473967],\n",
       "       [0.5702184 ],\n",
       "       [0.8483763 ],\n",
       "       [0.765681  ],\n",
       "       [0.18345636],\n",
       "       [0.6619985 ],\n",
       "       [0.39987773],\n",
       "       [0.7492575 ],\n",
       "       [0.9565457 ],\n",
       "       [0.5685554 ],\n",
       "       [0.6825426 ],\n",
       "       [0.87133896],\n",
       "       [0.6831622 ],\n",
       "       [0.8118692 ],\n",
       "       [0.665204  ],\n",
       "       [0.9394218 ],\n",
       "       [0.8038694 ],\n",
       "       [0.8329178 ],\n",
       "       [0.14254245],\n",
       "       [0.85353994],\n",
       "       [0.9880015 ],\n",
       "       [0.82924014],\n",
       "       [0.4537413 ],\n",
       "       [0.4988232 ],\n",
       "       [0.6754758 ],\n",
       "       [0.8231495 ],\n",
       "       [0.7188412 ],\n",
       "       [0.81992465],\n",
       "       [0.7916132 ],\n",
       "       [0.5864082 ],\n",
       "       [0.5772167 ],\n",
       "       [0.868195  ],\n",
       "       [0.6695273 ],\n",
       "       [0.7816111 ],\n",
       "       [0.90093184],\n",
       "       [0.92230374],\n",
       "       [0.30896562],\n",
       "       [0.30871075],\n",
       "       [0.59586984],\n",
       "       [0.84803075],\n",
       "       [0.41685385],\n",
       "       [0.74614495],\n",
       "       [0.52576363],\n",
       "       [0.49541917],\n",
       "       [0.71274257],\n",
       "       [0.77043486],\n",
       "       [0.4999289 ],\n",
       "       [0.73114073],\n",
       "       [0.68435574],\n",
       "       [0.8084911 ],\n",
       "       [0.8023612 ],\n",
       "       [0.7827046 ],\n",
       "       [0.92220235],\n",
       "       [0.80860317],\n",
       "       [0.599525  ],\n",
       "       [0.766489  ],\n",
       "       [0.8063823 ],\n",
       "       [0.7857917 ],\n",
       "       [0.6366551 ],\n",
       "       [0.8024839 ],\n",
       "       [0.63880014],\n",
       "       [0.6466709 ],\n",
       "       [0.6371568 ],\n",
       "       [0.30443472],\n",
       "       [0.89604306],\n",
       "       [0.57968414],\n",
       "       [0.6197715 ],\n",
       "       [0.7900466 ],\n",
       "       [0.24090302],\n",
       "       [0.8678497 ],\n",
       "       [0.58286875],\n",
       "       [0.83205783],\n",
       "       [0.7332219 ],\n",
       "       [0.8309705 ],\n",
       "       [0.46315598],\n",
       "       [0.8601925 ],\n",
       "       [0.6143493 ],\n",
       "       [0.88112164],\n",
       "       [0.7886025 ],\n",
       "       [0.57989794],\n",
       "       [0.5551843 ],\n",
       "       [0.44546053],\n",
       "       [0.736573  ],\n",
       "       [0.662613  ],\n",
       "       [0.72619665],\n",
       "       [0.7958604 ],\n",
       "       [0.29592156],\n",
       "       [0.53945625],\n",
       "       [0.61643195],\n",
       "       [0.6023986 ],\n",
       "       [0.7393381 ],\n",
       "       [0.61785173],\n",
       "       [0.5384944 ],\n",
       "       [0.5818405 ],\n",
       "       [0.7987152 ],\n",
       "       [0.61014134],\n",
       "       [0.6744584 ],\n",
       "       [0.28410995],\n",
       "       [0.47191358],\n",
       "       [0.6923431 ],\n",
       "       [0.23534667],\n",
       "       [0.6557672 ],\n",
       "       [0.55486524],\n",
       "       [0.7136071 ],\n",
       "       [0.6259201 ],\n",
       "       [0.75951576],\n",
       "       [0.47018164],\n",
       "       [0.52717716],\n",
       "       [0.58765155],\n",
       "       [0.7159041 ],\n",
       "       [0.48553166],\n",
       "       [0.44401124],\n",
       "       [0.8220295 ],\n",
       "       [0.5709218 ],\n",
       "       [0.75333005],\n",
       "       [0.7679801 ],\n",
       "       [0.79117584],\n",
       "       [0.7786689 ],\n",
       "       [0.94448864],\n",
       "       [0.8954326 ],\n",
       "       [0.5824897 ],\n",
       "       [0.68789715],\n",
       "       [0.5391111 ],\n",
       "       [0.7320947 ],\n",
       "       [0.3347525 ],\n",
       "       [0.3892529 ],\n",
       "       [0.641106  ],\n",
       "       [0.83272827],\n",
       "       [0.8294486 ],\n",
       "       [0.41203082],\n",
       "       [0.34462318],\n",
       "       [0.7228703 ],\n",
       "       [0.55029976],\n",
       "       [0.5714324 ],\n",
       "       [0.5127641 ],\n",
       "       [0.7990836 ],\n",
       "       [0.7228255 ],\n",
       "       [0.8380621 ],\n",
       "       [0.9640354 ],\n",
       "       [0.9699472 ],\n",
       "       [0.892151  ],\n",
       "       [0.6940299 ],\n",
       "       [0.703212  ],\n",
       "       [0.89539635],\n",
       "       [0.5182825 ],\n",
       "       [0.8566758 ],\n",
       "       [0.8675623 ],\n",
       "       [0.49705443],\n",
       "       [0.35891938],\n",
       "       [0.89822495],\n",
       "       [0.5753065 ],\n",
       "       [0.73082983],\n",
       "       [0.48799312],\n",
       "       [0.6873483 ],\n",
       "       [0.7661939 ],\n",
       "       [0.86623394],\n",
       "       [0.20870021],\n",
       "       [0.50097543],\n",
       "       [0.64023834],\n",
       "       [0.563777  ],\n",
       "       [0.8517864 ],\n",
       "       [0.71276265],\n",
       "       [0.39755082],\n",
       "       [0.90570855],\n",
       "       [0.67644525],\n",
       "       [0.7311754 ],\n",
       "       [0.7321137 ],\n",
       "       [0.6195041 ],\n",
       "       [0.9310913 ],\n",
       "       [0.75570476],\n",
       "       [0.27570122],\n",
       "       [0.865827  ],\n",
       "       [0.71489275],\n",
       "       [0.7493168 ],\n",
       "       [0.92555374],\n",
       "       [0.7482574 ],\n",
       "       [0.20726135],\n",
       "       [0.67732894],\n",
       "       [0.7000886 ],\n",
       "       [0.58472764],\n",
       "       [0.74714655],\n",
       "       [0.927927  ],\n",
       "       [0.27350342],\n",
       "       [0.9033942 ],\n",
       "       [0.9253745 ],\n",
       "       [0.8535191 ],\n",
       "       [0.23156464],\n",
       "       [0.5212016 ],\n",
       "       [0.3053374 ],\n",
       "       [0.81146145],\n",
       "       [0.7026586 ],\n",
       "       [0.77273464],\n",
       "       [0.65139824],\n",
       "       [0.6985145 ],\n",
       "       [0.354857  ],\n",
       "       [0.85076225],\n",
       "       [0.6256504 ],\n",
       "       [0.5017053 ],\n",
       "       [0.8743069 ],\n",
       "       [0.71118903],\n",
       "       [0.7261577 ],\n",
       "       [0.796479  ],\n",
       "       [0.7319069 ],\n",
       "       [0.72221863],\n",
       "       [0.57375336],\n",
       "       [0.65189034],\n",
       "       [0.9678652 ],\n",
       "       [0.4226417 ],\n",
       "       [0.6016134 ],\n",
       "       [0.35783973],\n",
       "       [0.37133995],\n",
       "       [0.7504106 ],\n",
       "       [0.6336181 ],\n",
       "       [0.4297668 ],\n",
       "       [0.8080375 ],\n",
       "       [0.67390007],\n",
       "       [0.33073515],\n",
       "       [0.6033744 ],\n",
       "       [0.7421379 ],\n",
       "       [0.7196286 ],\n",
       "       [0.6209625 ],\n",
       "       [0.600015  ],\n",
       "       [0.7602298 ],\n",
       "       [0.64335406],\n",
       "       [0.33758128],\n",
       "       [0.88394743],\n",
       "       [0.4846835 ],\n",
       "       [0.80667514],\n",
       "       [0.5683965 ],\n",
       "       [0.5151819 ],\n",
       "       [0.60700065],\n",
       "       [0.516245  ],\n",
       "       [0.59956634],\n",
       "       [0.7875509 ],\n",
       "       [0.632904  ],\n",
       "       [0.56948406],\n",
       "       [0.71363604],\n",
       "       [0.50438154],\n",
       "       [0.7909912 ],\n",
       "       [0.8238998 ],\n",
       "       [0.6810586 ],\n",
       "       [0.804814  ],\n",
       "       [0.7647206 ],\n",
       "       [0.9137275 ],\n",
       "       [0.77663124],\n",
       "       [0.6002251 ],\n",
       "       [0.34111452],\n",
       "       [0.27113387],\n",
       "       [0.49791718],\n",
       "       [0.64903486],\n",
       "       [0.9599323 ],\n",
       "       [0.5790439 ],\n",
       "       [0.6351656 ],\n",
       "       [0.86555105],\n",
       "       [0.9547899 ],\n",
       "       [0.25686938],\n",
       "       [0.9583621 ],\n",
       "       [0.7567594 ],\n",
       "       [0.38789085],\n",
       "       [0.681739  ],\n",
       "       [0.586166  ],\n",
       "       [0.8200934 ],\n",
       "       [0.88846886],\n",
       "       [0.5653165 ],\n",
       "       [0.8033058 ],\n",
       "       [0.7661891 ],\n",
       "       [0.502516  ],\n",
       "       [0.66496956],\n",
       "       [0.8950763 ],\n",
       "       [0.7892944 ],\n",
       "       [0.8455529 ],\n",
       "       [0.71098757],\n",
       "       [0.58626014],\n",
       "       [0.85960954],\n",
       "       [0.6594354 ],\n",
       "       [0.85414183],\n",
       "       [0.8483526 ],\n",
       "       [0.6503608 ],\n",
       "       [0.9700527 ],\n",
       "       [0.85112154],\n",
       "       [0.7024405 ],\n",
       "       [0.23981714],\n",
       "       [0.64585984],\n",
       "       [0.5777859 ],\n",
       "       [0.89120525],\n",
       "       [0.82707393],\n",
       "       [0.7160093 ],\n",
       "       [0.7282379 ],\n",
       "       [0.8129728 ],\n",
       "       [0.7056627 ],\n",
       "       [0.6976066 ],\n",
       "       [0.7363968 ],\n",
       "       [0.87199676],\n",
       "       [0.9182274 ],\n",
       "       [0.6642685 ],\n",
       "       [0.7045962 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd05203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
